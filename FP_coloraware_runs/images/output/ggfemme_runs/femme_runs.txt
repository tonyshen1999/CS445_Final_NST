RUNS 300 INPUT IMAGES  STYLE=femmeNueAssise.jpg, CONTENT=golden_gate.jpg
SIGMA =0.3 / 0.2
EPS = 1e-8
PALETTE_SIZE = 5
BLACK_AND_WHITE = FALSE

OPTIMIZER = 'LBFGS', LR = 0.5 #https://pytorch.org/docs/stable/generated/torch.optim.LBFGS.html            		     #lr=LEARNING RATE 
CONTENT / STYLE DISTANT L2
COLOR DISTANCE either L2 or chroma_L2
STYLE LOSS = large number: 1k 
CONTENT LOSS = 1
IMAGE SIZE 224

VGG19 MODEL WITH DEFAULT WEIGHTS
Content Loss: 54.632229 Color-Aware Loss: 29.672941 ggFemme_1kLoss_L2-sigma-pt20.jpg
Content Loss: 36.867565 Color-Aware Loss: 14.408978 ggFemme_1kLoss_chroma_L2-sigma-pt20.jpg

Content Loss: 45.226162 Color-Aware Loss: 21.242399 ggFemme_1kLoss_L2-sigma-pt25.jpg
Content Loss: 35.034523 Color-Aware Loss: 14.015418 ggFemme_1kLoss_chroma_L2-sigma-pt25.jpg
  

Content Loss: 40.485687 Color-Aware Loss: 16.586571 ggFemme_1kLoss_L2-sigma-pt30.jpg
Content Loss: 28.795990 Color-Aware Loss: 10.565065 ggFemme_1kLoss_chroma_L2-sigma-pt30.jpg

Try new run 0.30 and 50k loss:
Content Loss: 65.655670 Color-Aware Loss: 211.066986 ggFemme_50kLoss_chroma_L2-sigma-pt30.jpg

Try addition run 0.3 and 10k loss:
Content Loss: 47.268532 Color-Aware Loss: 45.949562 ggFemme_10kLoss_chroma_L2-sigma-pt30

